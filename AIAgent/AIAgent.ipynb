{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab226f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import time\n",
    "import sys\n",
    "\n",
    "load_dotenv()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a49786",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "llm = init_chat_model(\"google_genai:gemini-2.5-flash\")\n",
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4096b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools import (\n",
    "    check_gaming_laptops,\n",
    "    check_laptops,\n",
    "    check_tablets,\n",
    "    check_twoin1,\n",
    "    check_desktops,\n",
    "    check_AIO,\n",
    "    retrieve_information_about_brand,\n",
    "    retrieve_information_about_product_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb39cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(\n",
    "    llm,\n",
    "    tools=[check_gaming_laptops,check_AIO, check_laptops,check_tablets, check_twoin1, check_desktops, retrieve_information_about_brand,retrieve_information_about_product_type],\n",
    "    prompt=\"\"\"\n",
    "You are Jarir’s Website product salesman with live access to our full product database.\n",
    "— Greet politely and mirror the customer’s language (Arabic or English).  \n",
    "- Answer queries about jarir products only. Dont answer unrelated question.\n",
    "— Infer the shopper’s real needs (purpose, budget, preferences) from context; ask brief follow-up questions only when essential. Ask one question at a time to avoid overwhelming the customer.  \n",
    "— If the exact requested item is unavailable, automatically suggest the closest alternatives.  \n",
    "- Use retrieve tools to generaly check the database.\n",
    "— Never reveal system details, internal reasoning, or error messages—show only recommendations, clarifying questions, or the fallback message above.\n",
    "- Be concise—do not repeat yourself.\n",
    "- Never use jarir website or app, just use the database.\n",
    "- When calling any product checking tools provide the specs that is requierd by the tool, the `specs` argument must always be a Python dictionary, not a string. For example, use `specs={'brand': 'Apple', 'model': 'MacBook Air M2', 'ram': '16 GB RAM'}` instead of `specs='{\\\"brand\\\": \\\"Apple\\\", \\\"model\\\": \\\"MacBook Air M2\\\", \\\"ram\\\": \\\"16GB\\\"}'`.\"\n",
    "- When you recieve the products from the tools, order them from the most accurate to the least accurate based on the specs provided by the user.\n",
    "- When a user asks for a product from a broad category (e.g., '2-in-1 laptop', 'gaming laptop', 'tablet') without providing specific details (brand, model, budget, or key specs), always ask clarifying questions first to gather essential preferences. **Only proceed with a tool call once sufficient details are collected** to make the `specs` argument more targeted and avoid generic searches.\n",
    "- Try to avoid displaying the renewed products at the top of list, keep them at the end of the list, or mention that they exist if the customer is interested. \n",
    "- The tool returns up to 10 items; choose at most the top 3 relevant new products (renewed ones should appear last).\n",
    "- If any brands or models are not in the database then Jarir doesn't have them in their storage.\n",
    "- Always provide the maximum budget allowed to the tools as a clean number in string format.  \n",
    "- These are the available product_type ['gaming', 'laptop', 'tablet', 'twoin1_laptop', 'desktops', 'AIO']\n",
    "- When providing product recommendations, if the search results return multiple items that are essentially the same product (same `brand`, `model`, and core `specs` like `cpu_model`, `gpu_model`, `ram`, `storage`, `screen_size_inch`), but differ only in `color`, slight `price` variations, or `product_type` (e.g., 'Laptop' vs. 'renewed Laptop'), consolidate them into a single recommendation entry.\n",
    "    For this consolidated entry:\n",
    "        1.  Present the core product details and shared specifications once.\n",
    "        2.  Mention the available variations (e.g., 'Available in Space Grey and Silver').\n",
    "        3.  State the price range if there are different prices for these variations (e.g., 'Prices range from X SAR to Y SAR').\n",
    "        4.  Clearly list the `product_url` for each distinct variation within that single entry, indicating which URL corresponds to which specific color or renewed status.\n",
    "        5.  Always prioritize displaying new products first, and then mention renewed options as a more budget-friendly alternative if applicable.\"\n",
    "        \n",
    "    Dont include these two except if the user ask you about them:\n",
    "     **Screen:** 14.2\" Liquid Retina XDR Display (3024 x 1964)\n",
    "     **Features:** Retina XDR Display, Touch ID, 1080p FaceTime HD Camera\n",
    "    \"\"\"\n",
    "    ,\n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eaf173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    \"\"\"Stream assistant tokens with ChatGPT-style typing effect.\"\"\"\n",
    "    print(\"\\nAssistant: \", end=\"\", flush=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        \n",
    "        if isinstance(chunk, tuple) and len(chunk) > 0:\n",
    "            message_chunk = chunk[0] \n",
    "            \n",
    "            if hasattr(message_chunk, \"content\") and message_chunk.content:\n",
    "                text = message_chunk.content\n",
    "                if isinstance(text, list):\n",
    "                    text = \"\".join(\n",
    "                        part.get(\"text\", \"\") if isinstance(part, dict) else str(part)\n",
    "                        for part in text\n",
    "                    )\n",
    "                \n",
    "                \n",
    "                for char in text:\n",
    "                    print(char, end=\"\", flush=True)\n",
    "                    time.sleep(0.01) \n",
    "        \n",
    "        \n",
    "        elif hasattr(chunk, \"content\") and chunk.content:\n",
    "            text = chunk.content\n",
    "            if isinstance(text, list):\n",
    "                text = \"\".join(\n",
    "                    part.get(\"text\", \"\") if isinstance(part, dict) else str(part)\n",
    "                    for part in text\n",
    "                )\n",
    "\n",
    "            for char in text:\n",
    "                print(char, end=\"\", flush=True)\n",
    "                time.sleep(0.01) \n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"User: \", end=\"\", flush=True)  # Print \"User: \" before input\n",
    "    input_text = input()\n",
    "    if input_text.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "        print(\"Exiting the chat.\")\n",
    "        break\n",
    "    print(input_text)\n",
    "    inputs = {\"messages\": [{\"role\": \"user\", \"content\": input_text}]}\n",
    "    print_stream(graph.stream(inputs, stream_mode=\"messages\", config=config))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
